{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Data Structures and Algorithms in Python Implementation of various Algorithms and Data Structures in Python. The material is complied from a couple of sources, all of which are listed below. Although it primarily follows Algorithms YouTube playlist , by Abdul Bari .","title":"Home"},{"location":"#data-structures-and-algorithms-in-python","text":"Implementation of various Algorithms and Data Structures in Python. The material is complied from a couple of sources, all of which are listed below. Although it primarily follows Algorithms YouTube playlist , by Abdul Bari .","title":"Data Structures and Algorithms in Python"},{"location":"example/","text":"Data Structures and Algorithms in Python For full documentation visit mkdocs.org . Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Reference imperative_binary_search ( input_list , element_to_search ) Performs a binary search on the input_list to find the element_to_search , returns its index if found, else returns -1. Calculate average temperature from multiple measurements imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. Source code in dsa/algorithms/divide_and_conquer/binary_search.py def imperative_binary_search ( input_list : List [ int ], element_to_search : int ) -> int : \"\"\" Performs a binary search on the `input_list` to find the `element_to_search`, returns its index if found, else returns -1. Calculate average temperature from multiple measurements >>> imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 >>> imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. \"\"\" high = len ( input_list ) low = 0 mid = ( high + low ) // 2 while high - low > 1 : if input_list [ mid ] == element_to_search : return mid if element_to_search < input_list [ mid ]: high = mid mid = ( high + low ) // 2 elif element_to_search > input_list [ mid ]: low = mid mid = ( high + low ) // 2 else : if input_list [ low ] == element_to_search : return low else : return - 1 recursive_binary_search ( input_list , element_to_search ) Performs a binary search on the input_list to find the element_to_search , returns its index if found, else returns -1. Calculate average temperature from multiple measurements imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. Source code in dsa/algorithms/divide_and_conquer/binary_search.py def recursive_binary_search ( input_list : List [ int ], element_to_search : int ) -> int : \"\"\" Performs a binary search on the `input_list` to find the `element_to_search`, returns its index if found, else returns -1. Calculate average temperature from multiple measurements >>> imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 >>> imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. \"\"\" def _binary_search ( low : int , high : int ) -> int : nonlocal element_to_search nonlocal input_list if low == high : if input_list [ low ] == element_to_search : return low else : return - 1 else : mid = ( low + high ) // 2 if element_to_search == input_list [ mid ]: return mid if element_to_search < input_list [ mid ]: return _binary_search ( low , mid - 1 ) else : return _binary_search ( mid + 1 , high ) return _binary_search ( 0 , len ( input_list )) Details Nested Open styled details Nested details! And more content again. Normal Success Content. Warning Content. MathJax \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\) , \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\) . \\[ E(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j \\] \\[3 < 4\\] \\[\\begin{align} p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right) \\\\ p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right) \\end{align}\\] Superfence Flowchart graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; Sequence diagrams sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! State diagrams stateDiagram-v2 [*] --> Active state Active { [*] --> NumLockOff NumLockOff --> NumLockOn : EvNumLockPressed NumLockOn --> NumLockOff : EvNumLockPressed -- [*] --> CapsLockOff CapsLockOff --> CapsLockOn : EvCapsLockPressed CapsLockOn --> CapsLockOff : EvCapsLockPressed -- [*] --> ScrollLockOff ScrollLockOff --> ScrollLockOn : EvScrollLockPressed ScrollLockOn --> ScrollLockOff : EvScrollLockPressed } Class diagrams classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() } Entity-Relationship diagram erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! Large Diagram https://mermaid-js.github.io/mermaid/#/examples?id=basic-flowchart graph TB sq[Square shape] --> ci((Circle shape)) subgraph A od>Odd shape]-- Two line<br/>edge comment --> ro di{Diamond with <br/> line break} -.-> ro(Rounded<br>square<br>shape) di==>ro2(Rounded square shape) end %% Notice that no text in shape are added here instead that is appended further down e --> od3>Really long text with linebreak<br>in an Odd shape] %% Comments after double percent signs e((Inner / circle<br>and some odd <br>special characters)) --> f(,.?!+-*\u0632) cyr[Cyrillic]-->cyr2((Circle shape \u041d\u0430\u0447\u0430\u043b\u043e)); classDef green fill:#9f6,stroke:#333,stroke-width:2px; classDef orange fill:#f96,stroke:#333,stroke-width:4px; class sq,e green class di orange Implementation in various languages C C++ Python #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } def main () -> int : print ( \"Hello world!\" ) return 0 theme : features : - content.code.annotate # (1) I'm a code annotation! I can contain code , formatted text , images, ... basically anything that can be expressed in Markdown.","title":"Example"},{"location":"example/#data-structures-and-algorithms-in-python","text":"For full documentation visit mkdocs.org .","title":"Data Structures and Algorithms in Python"},{"location":"example/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"example/#reference","text":"","title":"Reference"},{"location":"example/#dsa.algorithms.divide_and_conquer.binary_search.imperative_binary_search","text":"Performs a binary search on the input_list to find the element_to_search , returns its index if found, else returns -1. Calculate average temperature from multiple measurements imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. Source code in dsa/algorithms/divide_and_conquer/binary_search.py def imperative_binary_search ( input_list : List [ int ], element_to_search : int ) -> int : \"\"\" Performs a binary search on the `input_list` to find the `element_to_search`, returns its index if found, else returns -1. Calculate average temperature from multiple measurements >>> imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 >>> imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. \"\"\" high = len ( input_list ) low = 0 mid = ( high + low ) // 2 while high - low > 1 : if input_list [ mid ] == element_to_search : return mid if element_to_search < input_list [ mid ]: high = mid mid = ( high + low ) // 2 elif element_to_search > input_list [ mid ]: low = mid mid = ( high + low ) // 2 else : if input_list [ low ] == element_to_search : return low else : return - 1","title":"imperative_binary_search()"},{"location":"example/#dsa.algorithms.divide_and_conquer.binary_search.recursive_binary_search","text":"Performs a binary search on the input_list to find the element_to_search , returns its index if found, else returns -1. Calculate average temperature from multiple measurements imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. Source code in dsa/algorithms/divide_and_conquer/binary_search.py def recursive_binary_search ( input_list : List [ int ], element_to_search : int ) -> int : \"\"\" Performs a binary search on the `input_list` to find the `element_to_search`, returns its index if found, else returns -1. Calculate average temperature from multiple measurements >>> imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 >>> imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. \"\"\" def _binary_search ( low : int , high : int ) -> int : nonlocal element_to_search nonlocal input_list if low == high : if input_list [ low ] == element_to_search : return low else : return - 1 else : mid = ( low + high ) // 2 if element_to_search == input_list [ mid ]: return mid if element_to_search < input_list [ mid ]: return _binary_search ( low , mid - 1 ) else : return _binary_search ( mid + 1 , high ) return _binary_search ( 0 , len ( input_list ))","title":"recursive_binary_search()"},{"location":"example/#details","text":"","title":"Details"},{"location":"example/#nested","text":"Open styled details Nested details! And more content again.","title":"Nested"},{"location":"example/#normal","text":"Success Content. Warning Content.","title":"Normal"},{"location":"example/#mathjax","text":"\\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\) , \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\) . \\[ E(\\mathbf{v}, \\mathbf{h}) = -\\sum_{i,j}w_{ij}v_i h_j - \\sum_i b_i v_i - \\sum_j c_j h_j \\] \\[3 < 4\\] \\[\\begin{align} p(v_i=1|\\mathbf{h}) & = \\sigma\\left(\\sum_j w_{ij}h_j + b_i\\right) \\\\ p(h_j=1|\\mathbf{v}) & = \\sigma\\left(\\sum_i w_{ij}v_i + c_j\\right) \\end{align}\\]","title":"MathJax"},{"location":"example/#superfence","text":"","title":"Superfence"},{"location":"example/#flowchart","text":"graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!];","title":"Flowchart"},{"location":"example/#sequence-diagrams","text":"sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good!","title":"Sequence diagrams"},{"location":"example/#state-diagrams","text":"stateDiagram-v2 [*] --> Active state Active { [*] --> NumLockOff NumLockOff --> NumLockOn : EvNumLockPressed NumLockOn --> NumLockOff : EvNumLockPressed -- [*] --> CapsLockOff CapsLockOff --> CapsLockOn : EvCapsLockPressed CapsLockOn --> CapsLockOff : EvCapsLockPressed -- [*] --> ScrollLockOff ScrollLockOff --> ScrollLockOn : EvScrollLockPressed ScrollLockOn --> ScrollLockOff : EvScrollLockPressed }","title":"State diagrams"},{"location":"example/#class-diagrams","text":"classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() }","title":"Class diagrams"},{"location":"example/#entity-relationship-diagram","text":"erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good!","title":"Entity-Relationship diagram"},{"location":"example/#large-diagram","text":"https://mermaid-js.github.io/mermaid/#/examples?id=basic-flowchart graph TB sq[Square shape] --> ci((Circle shape)) subgraph A od>Odd shape]-- Two line<br/>edge comment --> ro di{Diamond with <br/> line break} -.-> ro(Rounded<br>square<br>shape) di==>ro2(Rounded square shape) end %% Notice that no text in shape are added here instead that is appended further down e --> od3>Really long text with linebreak<br>in an Odd shape] %% Comments after double percent signs e((Inner / circle<br>and some odd <br>special characters)) --> f(,.?!+-*\u0632) cyr[Cyrillic]-->cyr2((Circle shape \u041d\u0430\u0447\u0430\u043b\u043e)); classDef green fill:#9f6,stroke:#333,stroke-width:2px; classDef orange fill:#f96,stroke:#333,stroke-width:4px; class sq,e green class di orange Implementation in various languages C C++ Python #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } def main () -> int : print ( \"Hello world!\" ) return 0 theme : features : - content.code.annotate # (1) I'm a code annotation! I can contain code , formatted text , images, ... basically anything that can be expressed in Markdown.","title":"Large Diagram"},{"location":"algorithms/analysis_of_algorithms/","tags":["algorithms"],"text":"Analysis of Algorithms Key characteristics of algorithms Input Output Definiteness -> Clear and Unambiguous Finiteness -> Effectiveness -> Nothing superfluous Important Metrics of Algorithm performance Time Space Network Consumption Power Consumption CPU registers For device drivers and other low-level algorithms, another metric of analyses could be the number of CPU registers the algorithm utilizes. Datatypes are decided at Program time, we don\u2019t usually care when we write pseudocode. Every simple statement, we assume takes 1 unit of time, Of course, this is really shallow, at machine-code this can change How deep we would want to go in an analysis is up to us. Example 1: Calculating Time and Space Complexity { temp = a ; a = b ; b = temp ; } \\(f(n) = 3\\) Frequency Count Method Sum of all elements in an array. sum ( A , n ) { s = 0 ; for ( i = 0 ; i < n ; i ++ ){ s = s + A [ i ] } return s ; } Analyses : Time Complexity Space Complexity i changes n+1 times, inside the loop the statements executed for n times. The first and return statement add 2 more the time complexity. \\(f(n) = 2n + 3 = O(n)\\) -> Order of n. A, n, s, I Just 3 variables, each is one word, and one array of size n. \\(S(n) = n + 3 = O(n)\\) -> Order of n. Sum of two matrices add ( A , B , n ) { for ( i = 0 ; i < n ; i ++ ) { # -> n + 1 for ( j = 0 ; j < n ; j ++ ) { # -> n x (n + 1) C [ i , j ] = A [ i , j ] + B [ i , j ]; # -> n x n } } } Analyses Time Complexity Space Complexity \\(f(n) = n + 1 + n^2 + n + n^2 = 2*n^2 + 2*n + 1 = O(n^2)\\) -> Order of \\(n^2\\) . \\(A\\) -> \\(n^2\\) , \\(B\\) -> \\(n^2\\) , \\(C\\) -> \\(n^2\\) , \\(n\\) -> \\(1\\) , \\(I\\) -> \\(1\\) , \\(j\\) -> \\(1\\) Total: \\(2*n^2 + 3 = O(n^2)\\) -> Order of \\(n^2\\) . Time Complexity Ceil of non-integer count Conditional statements -> Worst and Best case statements Class of Time Functions \\(O(1)\\) -> Constant \\(O(log n)\\) -> Logarithmic \\(O(n)\\) -> Linear \\(O(n^2)\\) -> Quadratic \\(O(n^3)\\) -> Cubix \\(O(2^n)\\) -> Exponential Class of Time Functions \\(1 < log n < root(n) < n < n * (log n) < n^2 < n^3 ... < 2^n < 3^n < ... < n^n\\) Asymptotic Notation Comes from Mathematics O -> big-oh -> Upper Bound of a Function \u03a9 -> big\u2014omega -> Lower Bound of function \u03b8 -> theta -> Average Bound Best and Average Recurrence Relations - Recursive Algorithms Master Theorem \\(T(n) = aT(b/n) + f(n)\\) Brilliant - Master Theorem","title":"Analysis Of Algorithms"},{"location":"algorithms/analysis_of_algorithms/#analysis-of-algorithms","text":"","title":"Analysis of Algorithms"},{"location":"algorithms/analysis_of_algorithms/#key-characteristics-of-algorithms","text":"Input Output Definiteness -> Clear and Unambiguous Finiteness -> Effectiveness -> Nothing superfluous","title":"Key characteristics of algorithms"},{"location":"algorithms/analysis_of_algorithms/#important-metrics-of-algorithm-performance","text":"Time Space Network Consumption Power Consumption CPU registers For device drivers and other low-level algorithms, another metric of analyses could be the number of CPU registers the algorithm utilizes. Datatypes are decided at Program time, we don\u2019t usually care when we write pseudocode. Every simple statement, we assume takes 1 unit of time, Of course, this is really shallow, at machine-code this can change How deep we would want to go in an analysis is up to us. Example 1: Calculating Time and Space Complexity { temp = a ; a = b ; b = temp ; } \\(f(n) = 3\\)","title":"Important Metrics of Algorithm performance"},{"location":"algorithms/analysis_of_algorithms/#frequency-count-method","text":"Sum of all elements in an array. sum ( A , n ) { s = 0 ; for ( i = 0 ; i < n ; i ++ ){ s = s + A [ i ] } return s ; } Analyses : Time Complexity Space Complexity i changes n+1 times, inside the loop the statements executed for n times. The first and return statement add 2 more the time complexity. \\(f(n) = 2n + 3 = O(n)\\) -> Order of n. A, n, s, I Just 3 variables, each is one word, and one array of size n. \\(S(n) = n + 3 = O(n)\\) -> Order of n. Sum of two matrices add ( A , B , n ) { for ( i = 0 ; i < n ; i ++ ) { # -> n + 1 for ( j = 0 ; j < n ; j ++ ) { # -> n x (n + 1) C [ i , j ] = A [ i , j ] + B [ i , j ]; # -> n x n } } } Analyses Time Complexity Space Complexity \\(f(n) = n + 1 + n^2 + n + n^2 = 2*n^2 + 2*n + 1 = O(n^2)\\) -> Order of \\(n^2\\) . \\(A\\) -> \\(n^2\\) , \\(B\\) -> \\(n^2\\) , \\(C\\) -> \\(n^2\\) , \\(n\\) -> \\(1\\) , \\(I\\) -> \\(1\\) , \\(j\\) -> \\(1\\) Total: \\(2*n^2 + 3 = O(n^2)\\) -> Order of \\(n^2\\) .","title":"Frequency Count Method"},{"location":"algorithms/analysis_of_algorithms/#time-complexity","text":"Ceil of non-integer count Conditional statements -> Worst and Best case statements","title":"Time Complexity"},{"location":"algorithms/analysis_of_algorithms/#class-of-time-functions","text":"\\(O(1)\\) -> Constant \\(O(log n)\\) -> Logarithmic \\(O(n)\\) -> Linear \\(O(n^2)\\) -> Quadratic \\(O(n^3)\\) -> Cubix \\(O(2^n)\\) -> Exponential Class of Time Functions \\(1 < log n < root(n) < n < n * (log n) < n^2 < n^3 ... < 2^n < 3^n < ... < n^n\\)","title":"Class of Time Functions"},{"location":"algorithms/analysis_of_algorithms/#asymptotic-notation","text":"Comes from Mathematics O -> big-oh -> Upper Bound of a Function \u03a9 -> big\u2014omega -> Lower Bound of function \u03b8 -> theta -> Average Bound","title":"Asymptotic Notation"},{"location":"algorithms/analysis_of_algorithms/#best-and-average","text":"","title":"Best and Average"},{"location":"algorithms/analysis_of_algorithms/#recurrence-relations-recursive-algorithms","text":"","title":"Recurrence Relations - Recursive Algorithms"},{"location":"algorithms/analysis_of_algorithms/#master-theorem","text":"\\(T(n) = aT(b/n) + f(n)\\) Brilliant - Master Theorem","title":"Master Theorem"},{"location":"algorithms/divide_and_conquer/","text":"Divide and Conquer A common strategy used to solve problems which can be divided to similar smaller problems. These smaller problems can then be solved and their outputs aggregated to solve the main problem. Some common applications of Divide and Conquer are below, they will have implementation as part of this repository. Binary Search Heap Sort Finding Maximum and Minimum Merge Sort Quick Sort Strassen's Matrix Multiplication","title":"Index"},{"location":"algorithms/divide_and_conquer/#divide-and-conquer","text":"A common strategy used to solve problems which can be divided to similar smaller problems. These smaller problems can then be solved and their outputs aggregated to solve the main problem. Some common applications of Divide and Conquer are below, they will have implementation as part of this repository. Binary Search Heap Sort Finding Maximum and Minimum Merge Sort Quick Sort Strassen's Matrix Multiplication","title":"Divide and Conquer"},{"location":"algorithms/divide_and_conquer/binary_search/","text":"Binary Search Requires a sorted array. Time Complexity: \\(O(log n)\\) Implementation of Binary Search in Python Performs a binary search on the input_list to find the element_to_search , returns its index if found, else returns -1. Calculate average temperature from multiple measurements imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. Source code in dsa/algorithms/divide_and_conquer/binary_search.py def imperative_binary_search ( input_list : List [ int ], element_to_search : int ) -> int : \"\"\" Performs a binary search on the `input_list` to find the `element_to_search`, returns its index if found, else returns -1. Calculate average temperature from multiple measurements >>> imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 >>> imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. \"\"\" high = len ( input_list ) low = 0 mid = ( high + low ) // 2 while high - low > 1 : if input_list [ mid ] == element_to_search : return mid if element_to_search < input_list [ mid ]: high = mid mid = ( high + low ) // 2 elif element_to_search > input_list [ mid ]: low = mid mid = ( high + low ) // 2 else : if input_list [ low ] == element_to_search : return low else : return - 1","title":"Binary Search"},{"location":"algorithms/divide_and_conquer/binary_search/#binary-search","text":"Requires a sorted array. Time Complexity: \\(O(log n)\\) Implementation of Binary Search in Python Performs a binary search on the input_list to find the element_to_search , returns its index if found, else returns -1. Calculate average temperature from multiple measurements imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. Source code in dsa/algorithms/divide_and_conquer/binary_search.py def imperative_binary_search ( input_list : List [ int ], element_to_search : int ) -> int : \"\"\" Performs a binary search on the `input_list` to find the `element_to_search`, returns its index if found, else returns -1. Calculate average temperature from multiple measurements >>> imperative_binary_search([10, 11, 13, 34, 91, 101, 137], 127) -1 >>> imperative_binary_search([10, 11, 13, 34, 91, 127, 138], 127) 5 :param input_list: The list on which binary search is to be performed. :param element_to_search: Element to search for :return: Index of the element if found, otherwise -1. \"\"\" high = len ( input_list ) low = 0 mid = ( high + low ) // 2 while high - low > 1 : if input_list [ mid ] == element_to_search : return mid if element_to_search < input_list [ mid ]: high = mid mid = ( high + low ) // 2 elif element_to_search > input_list [ mid ]: low = mid mid = ( high + low ) // 2 else : if input_list [ low ] == element_to_search : return low else : return - 1","title":"Binary Search"},{"location":"algorithms/divide_and_conquer/binary_search/#dsa.algorithms.divide_and_conquer.binary_search.imperative_binary_search","text":"","title":"dsa.algorithms.divide_and_conquer.binary_search.imperative_binary_search"},{"location":"algorithms/divide_and_conquer/heap_sort/","text":"Heap Sort Heap Sort utilizes on Binary Tree, more special case of a Binary Tree called a Heap. So, we have to take a short detour, towards Data Structures, to explain Binary Trees and their characteristics. Binary Tree A Binary Tree is a type of tree data structure in which every node has at most two child nodes, a left node and a right node. Array Representation of Binary Tree Representing a Binary Tree as an array would go something like this, We would start from the top the root node would be the first element of the array. And, then we would go down one level, start from the left and go towards the right, the left-most element in the level would be the next element in the array. If certain nodes do not have children then, leave a null value for them in the array representation. graph TD A[60 - index 0] --> B[50 - index 1]; B --> C[16 - index 2]; B --> D[15 - index 3]; C --> E[10 - index 4]; C --> F[9 - index 5]; D --> G[8 - index 6]; D --> H[7 - index 7]; An array representation of this tree would be, [60, 50, 16, 15, 10, 9, 8, 7] . graph TD A[60 - index 0] --> B[50 - index 1]; B --> C[16 - index 3]; B --> D[15 - index 4]; A --> H[25 - index 2]; H --> I[32 - index 5]; H --> J[31 - index 6]; An array representation of this tree would be, [60, 50, 25, 16, 15, 32, 31] . graph TD A[60 - index 0] --> B[50 - index 1]; B --left-node--> C[16 - index 3]; A --> H[25 - index 2]; H --> I[32 - index 4]; H --> J[31 - index 5]; An array representation of this tree would be, [60, 50, 25, 16, None, 32, 31] . Node I added disambiguation to denote the left node, as mermaid-js automatically centers child nodes when only one exists. Formally, this would mean: If a node is at index \\(x - i\\) , the left child of the node should be at index \\(2*i\\) and the right child of the node should be at index \\(2*(i+1)\\) . For a particular node at index \\(i\\) in the array representation its parent Node would be at \\(i/2\\) . Full Binary Tree A Binary Tree is Full , when all nodes except the leaf nodes have two child nodes. Alternative definition would be, a binary tree with maximum number of nodes is called a Full binary tree. The maximum number of nodes would be, \\(2^(h + 1) - 1\\) where \\(h\\) is the height of the binary tree. The below is an example. graph TD A[60] --> B[50]; B --> C[16]; A --> H[25]; B --> D[15]; H --> I[32]; H --> J[31]; Complete Binary Tree also called a Heap A Complete Binary Tree is a Binary Tree which has no gaps when represented as an array, this is also referred to as a Heap . Heaps are also used a Priority Queues . Max Heap is a Complete Binary Tree where all parent nodes are of greater value than or equal to the values of their child nodes, and the root node has the greatest value. graph TD A[60] --> B[50]; B --> C[32]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; Min Heap is a Complete Binary Tree where all parent nodes have values lesser than or equal to the values of their child nodes, so the root node has the least value. graph TD A[16] --> B[50]; B --> C[72]; A --> H[25]; B --> D[60]; H --> I[37]; H --> J[33]; Inserting and Deleting Elements from a Heap Insertion on a Max Heap A new element is added at the left-most bottom node, that is the end of the array representation. Then, if the new node has a value greater than its parent i.e. the binary tree is no longer a Max Heap, the binary tree is then reorganized by shuffling parent and child nodes until it transforms into a Max Heap again. So, if the new node's value is greater than its immediate parent node, the new node is bubbled upwards in the binary tree until new node's parent has a greater value, it might even become the root node of the tree if its value is greater than all of its parents. Time Complexity Worst-case complexity of insertion on a Max Heap is \\(O(log n)\\) , happens when the new node has a value greater than all the nodes, as then the new node would have to be bubbled up to the root. So then we would have to traverse the height of the binary tree, which for a Complete Binary Tree is \\(log n\\) , where \\(n\\) is the number of nodes in the binary tree. The best-case complexity would be \\(O(1)\\) , happens when the new node's value is lower than its parent, no reorganization would be required. Insertion For example, if a new node with value \\(57\\) is inserted into this Max Heap. As the new node's value is greater than its immediate parent \\(32\\) , after the insertion binary tree would temporarily cease to be a Max Heap until reorganization. Insertion Step 0 graph TD A[60] --> B[50]; B --> C[32]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; subgraph insert-node-0 C --> K[57]; end Insertion Step 1 graph TD A[60] --> B[50]; subgraph insert-node-1 B --> K[57]; end A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; K --> C[32]; Insertion Step 2 graph TD subgraph insert-node-2 A[60] --> K[57]; end K --> B[50]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; B --> C[32]; Deletion on a Max Heap Only the root element is deleted, the rest of the binary tree is reorganized to form a Max Heap again. Then, the right most element on the last level of the binary tree is then moved to the root of tree, as moving any other node would make the binary tree in-complete . In other words, for the purposes of deletion the first element in the array representation of Max Heap is removed, and then the last element is moved to the root, pending reorganization. The next deletion, post reorganization would give us the next largest element, as it will be new root delete. On a Min Heap, this would be the opposite, as the root element would be the least element. Deletion For example, for deleting an element from this Heap, we would delete the node with value 60. Deletion Step 0 graph TD A[60 to-be-deleted] --> B[50]; B --> C[32]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; style A fill:red,stroke:#333,stroke-width:4px Deletion Step 1 graph TD subgraph delete-node-2 H[25] --> I[17]; H --> J[16]; end subgraph delete-node-1 B[50] --> C[32]; B --> D[31]; end Deletion Step 2 graph TD subgraph delete-node-2 H[25] --left-node--> I[17]; end subgraph delete-node-1 B[50] --> C[32]; B --> D[31]; end subgraph moved-node J[16] --> B; J --> H; end style J fill:green,stroke:#333,stroke-width:4px Deletion Step 3: Making the Binary Tree a Max Heap again graph TD H[25] --left-node--> I[17]; J[16] --> C[32]; J --> D[31]; subgraph reorganized-node B[50] --> J; end B --> H; style J fill:green,stroke:#333,stroke-width:4px graph TD H[25] --left-node--> I[17]; B[50] --> C[32]; C --> D[31]; subgraph reorganized-node C[32] --> J[16]; end B --> H; style J fill:green,stroke:#333,stroke-width:4px Time Complexity Deletion has a time complexity of \\(O(log n)\\) . All average, best and worst-case time complexities are equal to \\(O(log n)\\) . Heapify Naive Creation of Heap The naive way of creating a Heap, requires to insert each individual element one by one, and let the insert method organize the binary tree to a form a complete binary tree. This would have a time complexity of \\(O(n * log n)\\) Creation of Heap using Heapify A more efficient way of creating a Heap, with \\(O(n)\\) time complexity. Priority Queue Max or Min Heap let us express Priority Queues. That is when we want to the item in a queue that has the highest or lowest priority. As, when new items are inserted, they bubbled up the binary tree based on their value, or in this case a priority. The next deletion would return the item with the highest priority.","title":"Heap Sort"},{"location":"algorithms/divide_and_conquer/heap_sort/#heap-sort","text":"Heap Sort utilizes on Binary Tree, more special case of a Binary Tree called a Heap. So, we have to take a short detour, towards Data Structures, to explain Binary Trees and their characteristics.","title":"Heap Sort"},{"location":"algorithms/divide_and_conquer/heap_sort/#binary-tree","text":"A Binary Tree is a type of tree data structure in which every node has at most two child nodes, a left node and a right node.","title":"Binary Tree"},{"location":"algorithms/divide_and_conquer/heap_sort/#array-representation-of-binary-tree","text":"Representing a Binary Tree as an array would go something like this, We would start from the top the root node would be the first element of the array. And, then we would go down one level, start from the left and go towards the right, the left-most element in the level would be the next element in the array. If certain nodes do not have children then, leave a null value for them in the array representation. graph TD A[60 - index 0] --> B[50 - index 1]; B --> C[16 - index 2]; B --> D[15 - index 3]; C --> E[10 - index 4]; C --> F[9 - index 5]; D --> G[8 - index 6]; D --> H[7 - index 7]; An array representation of this tree would be, [60, 50, 16, 15, 10, 9, 8, 7] . graph TD A[60 - index 0] --> B[50 - index 1]; B --> C[16 - index 3]; B --> D[15 - index 4]; A --> H[25 - index 2]; H --> I[32 - index 5]; H --> J[31 - index 6]; An array representation of this tree would be, [60, 50, 25, 16, 15, 32, 31] . graph TD A[60 - index 0] --> B[50 - index 1]; B --left-node--> C[16 - index 3]; A --> H[25 - index 2]; H --> I[32 - index 4]; H --> J[31 - index 5]; An array representation of this tree would be, [60, 50, 25, 16, None, 32, 31] . Node I added disambiguation to denote the left node, as mermaid-js automatically centers child nodes when only one exists. Formally, this would mean: If a node is at index \\(x - i\\) , the left child of the node should be at index \\(2*i\\) and the right child of the node should be at index \\(2*(i+1)\\) . For a particular node at index \\(i\\) in the array representation its parent Node would be at \\(i/2\\) .","title":"Array Representation of Binary Tree"},{"location":"algorithms/divide_and_conquer/heap_sort/#full-binary-tree","text":"A Binary Tree is Full , when all nodes except the leaf nodes have two child nodes. Alternative definition would be, a binary tree with maximum number of nodes is called a Full binary tree. The maximum number of nodes would be, \\(2^(h + 1) - 1\\) where \\(h\\) is the height of the binary tree. The below is an example. graph TD A[60] --> B[50]; B --> C[16]; A --> H[25]; B --> D[15]; H --> I[32]; H --> J[31];","title":"Full Binary Tree"},{"location":"algorithms/divide_and_conquer/heap_sort/#complete-binary-tree-also-called-a-heap","text":"A Complete Binary Tree is a Binary Tree which has no gaps when represented as an array, this is also referred to as a Heap . Heaps are also used a Priority Queues . Max Heap is a Complete Binary Tree where all parent nodes are of greater value than or equal to the values of their child nodes, and the root node has the greatest value. graph TD A[60] --> B[50]; B --> C[32]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; Min Heap is a Complete Binary Tree where all parent nodes have values lesser than or equal to the values of their child nodes, so the root node has the least value. graph TD A[16] --> B[50]; B --> C[72]; A --> H[25]; B --> D[60]; H --> I[37]; H --> J[33];","title":"Complete Binary Tree also called a Heap"},{"location":"algorithms/divide_and_conquer/heap_sort/#inserting-and-deleting-elements-from-a-heap","text":"","title":"Inserting and Deleting Elements from a Heap"},{"location":"algorithms/divide_and_conquer/heap_sort/#insertion-on-a-max-heap","text":"A new element is added at the left-most bottom node, that is the end of the array representation. Then, if the new node has a value greater than its parent i.e. the binary tree is no longer a Max Heap, the binary tree is then reorganized by shuffling parent and child nodes until it transforms into a Max Heap again. So, if the new node's value is greater than its immediate parent node, the new node is bubbled upwards in the binary tree until new node's parent has a greater value, it might even become the root node of the tree if its value is greater than all of its parents.","title":"Insertion on a Max Heap"},{"location":"algorithms/divide_and_conquer/heap_sort/#time-complexity","text":"Worst-case complexity of insertion on a Max Heap is \\(O(log n)\\) , happens when the new node has a value greater than all the nodes, as then the new node would have to be bubbled up to the root. So then we would have to traverse the height of the binary tree, which for a Complete Binary Tree is \\(log n\\) , where \\(n\\) is the number of nodes in the binary tree. The best-case complexity would be \\(O(1)\\) , happens when the new node's value is lower than its parent, no reorganization would be required. Insertion For example, if a new node with value \\(57\\) is inserted into this Max Heap. As the new node's value is greater than its immediate parent \\(32\\) , after the insertion binary tree would temporarily cease to be a Max Heap until reorganization. Insertion Step 0 graph TD A[60] --> B[50]; B --> C[32]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; subgraph insert-node-0 C --> K[57]; end Insertion Step 1 graph TD A[60] --> B[50]; subgraph insert-node-1 B --> K[57]; end A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; K --> C[32]; Insertion Step 2 graph TD subgraph insert-node-2 A[60] --> K[57]; end K --> B[50]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; B --> C[32];","title":"Time Complexity"},{"location":"algorithms/divide_and_conquer/heap_sort/#deletion-on-a-max-heap","text":"Only the root element is deleted, the rest of the binary tree is reorganized to form a Max Heap again. Then, the right most element on the last level of the binary tree is then moved to the root of tree, as moving any other node would make the binary tree in-complete . In other words, for the purposes of deletion the first element in the array representation of Max Heap is removed, and then the last element is moved to the root, pending reorganization. The next deletion, post reorganization would give us the next largest element, as it will be new root delete. On a Min Heap, this would be the opposite, as the root element would be the least element. Deletion For example, for deleting an element from this Heap, we would delete the node with value 60. Deletion Step 0 graph TD A[60 to-be-deleted] --> B[50]; B --> C[32]; A --> H[25]; B --> D[31]; H --> I[17]; H --> J[16]; style A fill:red,stroke:#333,stroke-width:4px Deletion Step 1 graph TD subgraph delete-node-2 H[25] --> I[17]; H --> J[16]; end subgraph delete-node-1 B[50] --> C[32]; B --> D[31]; end Deletion Step 2 graph TD subgraph delete-node-2 H[25] --left-node--> I[17]; end subgraph delete-node-1 B[50] --> C[32]; B --> D[31]; end subgraph moved-node J[16] --> B; J --> H; end style J fill:green,stroke:#333,stroke-width:4px Deletion Step 3: Making the Binary Tree a Max Heap again graph TD H[25] --left-node--> I[17]; J[16] --> C[32]; J --> D[31]; subgraph reorganized-node B[50] --> J; end B --> H; style J fill:green,stroke:#333,stroke-width:4px graph TD H[25] --left-node--> I[17]; B[50] --> C[32]; C --> D[31]; subgraph reorganized-node C[32] --> J[16]; end B --> H; style J fill:green,stroke:#333,stroke-width:4px","title":"Deletion on a Max Heap"},{"location":"algorithms/divide_and_conquer/heap_sort/#time-complexity_1","text":"Deletion has a time complexity of \\(O(log n)\\) . All average, best and worst-case time complexities are equal to \\(O(log n)\\) .","title":"Time Complexity"},{"location":"algorithms/divide_and_conquer/heap_sort/#heapify","text":"","title":"Heapify"},{"location":"algorithms/divide_and_conquer/heap_sort/#naive-creation-of-heap","text":"The naive way of creating a Heap, requires to insert each individual element one by one, and let the insert method organize the binary tree to a form a complete binary tree. This would have a time complexity of \\(O(n * log n)\\)","title":"Naive Creation of Heap"},{"location":"algorithms/divide_and_conquer/heap_sort/#creation-of-heap-using-heapify","text":"A more efficient way of creating a Heap, with \\(O(n)\\) time complexity.","title":"Creation of Heap using Heapify"},{"location":"algorithms/divide_and_conquer/heap_sort/#priority-queue","text":"Max or Min Heap let us express Priority Queues. That is when we want to the item in a queue that has the highest or lowest priority. As, when new items are inserted, they bubbled up the binary tree based on their value, or in this case a priority. The next deletion would return the item with the highest priority.","title":"Priority Queue"},{"location":"algorithms/divide_and_conquer/merge_sort/","text":"Merge Sort Merge Operation The most fundamental operation of the Merge Sort, is the merge operations, which can take a number of sorted arrays and merge them into another sorted array. The most common of which is a Two Way Merge , which takes two arrays as input and merges them. The most general form of which is an m Way Merge, but these can be modeled with a repetitive 2-way merge. Two Way Merge [0, 2, 4, 6] [0, 3, 6, 9] --> [0, 0, 2, 3, 4, 6, 6, 9] graph TD D[[0, 2, 4, 6]] --> C{Merge} E[[0, 3, 6, 9]] --> C C --> B[[0, 0, 2, 3, 4, 6, 6, 9]] Two Way Merge Sort Break down an array to be sorted, till there are only two elements. An array with only one element is sorted, by virtue of having only one element. Merge Sort A recursive algorithm. \\(\\theta(n * log n)\\) Time Complexity Time complexity of Two Way Merge sort is \\(O(n * log n)\\) Applications Large Sized List Linked List It is really easy to perform merge operation on Linked List, we do not need to create temporary 3rd array. External Sorting of huge data When the data that needs to be sorted exceed the available RAM, merge sort can be used to piece-wise sorting and while storing the intermediate result on disk. Stable Order of duplicates is maintained. Cons Extra Place Not an inplace sort This is however not need in the case of LinkedList No small problem, for a small size it is slower. Insertion Sort \\(O(n^2)\\) -> Also Stable Merge Sort \\(O(n log n))\\) Bubble Sort \\(O(n^2)\\) -> Also Stable Recursive, all recursive algorithms use the stack, need more memory due the requirements of many stacks.","title":"Merge Sort"},{"location":"algorithms/divide_and_conquer/merge_sort/#merge-sort","text":"","title":"Merge Sort"},{"location":"algorithms/divide_and_conquer/merge_sort/#merge-operation","text":"The most fundamental operation of the Merge Sort, is the merge operations, which can take a number of sorted arrays and merge them into another sorted array. The most common of which is a Two Way Merge , which takes two arrays as input and merges them. The most general form of which is an m Way Merge, but these can be modeled with a repetitive 2-way merge. Two Way Merge [0, 2, 4, 6] [0, 3, 6, 9] --> [0, 0, 2, 3, 4, 6, 6, 9] graph TD D[[0, 2, 4, 6]] --> C{Merge} E[[0, 3, 6, 9]] --> C C --> B[[0, 0, 2, 3, 4, 6, 6, 9]]","title":"Merge Operation"},{"location":"algorithms/divide_and_conquer/merge_sort/#two-way-merge-sort","text":"Break down an array to be sorted, till there are only two elements. An array with only one element is sorted, by virtue of having only one element.","title":"Two Way Merge Sort"},{"location":"algorithms/divide_and_conquer/merge_sort/#merge-sort_1","text":"A recursive algorithm. \\(\\theta(n * log n)\\)","title":"Merge Sort"},{"location":"algorithms/divide_and_conquer/merge_sort/#time-complexity","text":"Time complexity of Two Way Merge sort is \\(O(n * log n)\\)","title":"Time Complexity"},{"location":"algorithms/divide_and_conquer/merge_sort/#applications","text":"Large Sized List Linked List It is really easy to perform merge operation on Linked List, we do not need to create temporary 3rd array. External Sorting of huge data When the data that needs to be sorted exceed the available RAM, merge sort can be used to piece-wise sorting and while storing the intermediate result on disk. Stable Order of duplicates is maintained.","title":"Applications"},{"location":"algorithms/divide_and_conquer/merge_sort/#cons","text":"Extra Place Not an inplace sort This is however not need in the case of LinkedList No small problem, for a small size it is slower. Insertion Sort \\(O(n^2)\\) -> Also Stable Merge Sort \\(O(n log n))\\) Bubble Sort \\(O(n^2)\\) -> Also Stable Recursive, all recursive algorithms use the stack, need more memory due the requirements of many stacks.","title":"Cons"},{"location":"algorithms/divide_and_conquer/quick_sort/","text":"Quick Sort Quick Sort another sorting algorithms that uses divide and conquer strategy. Pivot Element A fundamental part of quick sort is a something called a Pivot Element , it is the element in the array that is in the right place. By that we mean, all the elements to the Pivot Element's left are lower than it and all elements to its right are greater than it. Pivot element For example, in this array [8, 4, 3, 10, 12, 11, 32, 47] , 10 would be a pivot element. Algorithm Pivot elements allow use to apply to divide and conquer technique to the sorting of the array. The two new and separate sub-problems here then would be, the sorting of two slices of the arrays to the left and right of the pivot element. This process can be applied recursively until all elements are in their right place. Finding a Pivot element Portioning is the process of finding the pivot element and create one if non-exists. Analysis Time Complexity The time complexity of this recursive algorithm, where we partition each array into two arrays at each level of recursion. Best Case If the Pivot element at every recursion is a the median of that array, that it is apears at the middle of the array. Then, the array is divided in half at each recursion. The Time Complexity would be \\(O(n * logn)\\) . But, we do not know the median upfront, and cannot ensure that the median and pivot element are the same. Pivot element For example, here [1, 2, 3, 4, 5, 6, 7] , if 4 is chosen as a pivot element, it is also the median of the array. The array would be partitioned in two equal half for the next recursion. Worst Case Worst case occurs, when the partition occurs at the beginning of the list. The Time Complexity would be \\(O(n^2)\\) . Pivot element For example, here [2, 4, 8, 10, 16, 18, 17] , if 2 is chosen as a pivot element. Then the array would be partitioned, with only on element on the one of the partitions. Improving Worst Case Always select the middle element as pivot. Select a random element as pivot. Memory Complexity Best case is \\(log n\\) , as there \\(log n\\) recursions and stacks. Worst case is \\(n\\) , as there \\(n\\) recursions and stacks.","title":"Quick Sort"},{"location":"algorithms/divide_and_conquer/quick_sort/#quick-sort","text":"Quick Sort another sorting algorithms that uses divide and conquer strategy.","title":"Quick Sort"},{"location":"algorithms/divide_and_conquer/quick_sort/#pivot-element","text":"A fundamental part of quick sort is a something called a Pivot Element , it is the element in the array that is in the right place. By that we mean, all the elements to the Pivot Element's left are lower than it and all elements to its right are greater than it. Pivot element For example, in this array [8, 4, 3, 10, 12, 11, 32, 47] , 10 would be a pivot element.","title":"Pivot Element"},{"location":"algorithms/divide_and_conquer/quick_sort/#algorithm","text":"Pivot elements allow use to apply to divide and conquer technique to the sorting of the array. The two new and separate sub-problems here then would be, the sorting of two slices of the arrays to the left and right of the pivot element. This process can be applied recursively until all elements are in their right place.","title":"Algorithm"},{"location":"algorithms/divide_and_conquer/quick_sort/#finding-a-pivot-element","text":"Portioning is the process of finding the pivot element and create one if non-exists.","title":"Finding a Pivot element"},{"location":"algorithms/divide_and_conquer/quick_sort/#analysis","text":"","title":"Analysis"},{"location":"algorithms/divide_and_conquer/quick_sort/#time-complexity","text":"The time complexity of this recursive algorithm, where we partition each array into two arrays at each level of recursion. Best Case If the Pivot element at every recursion is a the median of that array, that it is apears at the middle of the array. Then, the array is divided in half at each recursion. The Time Complexity would be \\(O(n * logn)\\) . But, we do not know the median upfront, and cannot ensure that the median and pivot element are the same. Pivot element For example, here [1, 2, 3, 4, 5, 6, 7] , if 4 is chosen as a pivot element, it is also the median of the array. The array would be partitioned in two equal half for the next recursion. Worst Case Worst case occurs, when the partition occurs at the beginning of the list. The Time Complexity would be \\(O(n^2)\\) . Pivot element For example, here [2, 4, 8, 10, 16, 18, 17] , if 2 is chosen as a pivot element. Then the array would be partitioned, with only on element on the one of the partitions.","title":"Time Complexity"},{"location":"algorithms/divide_and_conquer/quick_sort/#improving-worst-case","text":"Always select the middle element as pivot. Select a random element as pivot.","title":"Improving Worst Case"},{"location":"algorithms/divide_and_conquer/quick_sort/#memory-complexity","text":"Best case is \\(log n\\) , as there \\(log n\\) recursions and stacks. Worst case is \\(n\\) , as there \\(n\\) recursions and stacks.","title":"Memory Complexity"},{"location":"algorithms/divide_and_conquer/strassens_matrix_multiplication/","text":"Strassen's Matrix Multiplication Time Complexity of naive way of implementing this would be \\(O(n^3)\\) . Matrix Multiplication For example, here [1, 2, 3, 4, 5, 6, 7] , if 4 is chosen as a pivot element, it is also the median of the array. The array would be partitioned in two equal half for the next recursion. \\[\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\\\ \\end{bmatrix}\\] \\[\\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\\\ \\end{bmatrix}\\] \\[\\begin{bmatrix} c_{11} & c_{12} \\\\ c_{21} & c_{22} \\\\ \\end{bmatrix}\\] \\(A * B = C\\) \\(c_{11} = a_{11}*b_{11} + a_{12}*b_{21}\\) Algorithm func mm(A, B, n): if (n <= 2): perform normal matrix multiplication else: mid = n // 2 mm(A11,B11,mid) + md(A12,B21,mid) mm(A11,B12,mid) + md(A12,B22,mid) mm(A21,B11,mid) + md(A22,B21,mid) mm(A21,B12,mid) + md(A22,B22,mid) Time Complexity This is recursive algorithm. f(n) = \\begin{cases} n/2, & \\text{if \\(n\\) is even} \\ 3n+1, & \\text{if \\(n\\) is odd} \\end{cases} \\left. \\begin{array}{l} \\text{if \\(n\\) is even:}&n/2\\ \\text{if \\(n\\) is odd:}&3n+1 \\end{array} \\right} =T(n) $T(n) = 8*T(n/2) + n^2 $. Time Complexity is \\(\\theta(n^3)\\) . Strassen's Matrix M Time Complexity is \\(O(n^{2.81})\\) .","title":"Strassen's Matrix Multiplication"},{"location":"algorithms/divide_and_conquer/strassens_matrix_multiplication/#strassens-matrix-multiplication","text":"Time Complexity of naive way of implementing this would be \\(O(n^3)\\) . Matrix Multiplication For example, here [1, 2, 3, 4, 5, 6, 7] , if 4 is chosen as a pivot element, it is also the median of the array. The array would be partitioned in two equal half for the next recursion. \\[\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\\\ \\end{bmatrix}\\] \\[\\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\\\ \\end{bmatrix}\\] \\[\\begin{bmatrix} c_{11} & c_{12} \\\\ c_{21} & c_{22} \\\\ \\end{bmatrix}\\] \\(A * B = C\\) \\(c_{11} = a_{11}*b_{11} + a_{12}*b_{21}\\)","title":"Strassen's Matrix Multiplication"},{"location":"algorithms/divide_and_conquer/strassens_matrix_multiplication/#algorithm","text":"func mm(A, B, n): if (n <= 2): perform normal matrix multiplication else: mid = n // 2 mm(A11,B11,mid) + md(A12,B21,mid) mm(A11,B12,mid) + md(A12,B22,mid) mm(A21,B11,mid) + md(A22,B21,mid) mm(A21,B12,mid) + md(A22,B22,mid)","title":"Algorithm"},{"location":"algorithms/divide_and_conquer/strassens_matrix_multiplication/#time-complexity","text":"This is recursive algorithm. f(n) = \\begin{cases} n/2, & \\text{if \\(n\\) is even} \\ 3n+1, & \\text{if \\(n\\) is odd} \\end{cases} \\left. \\begin{array}{l} \\text{if \\(n\\) is even:}&n/2\\ \\text{if \\(n\\) is odd:}&3n+1 \\end{array} \\right} =T(n) $T(n) = 8*T(n/2) + n^2 $. Time Complexity is \\(\\theta(n^3)\\) .","title":"Time Complexity"},{"location":"algorithms/divide_and_conquer/strassens_matrix_multiplication/#strassens-matrix-m","text":"Time Complexity is \\(O(n^{2.81})\\) .","title":"Strassen's Matrix M"},{"location":"algorithms/greedy_method/","text":"Greedy Method A common strategy used to solve problems. Useful in solving optimization problems, the problems which require minimum or maximum result. Optimizations problems can be solved using the below approaches: * Greedy Method * Dynamic Programming * Branch and Bound Greedy Method While looping over stuff, check if it is feasible solution to the problem. n = 5 a = [a1, a2, a3, a4, a5] algo greedy(a, n) { for i = 1 to n do { x = select(a); if is_feasible(x) then { solution = solution + x; } } } n = 5 a = [ a1 , a2 , a3 , a4 , a5 ] def greedy ( a , n ): for i in range ( 1 , n + 1 ): x = select ( a ) if is_feasible ( x ): solution = solution + x ;","title":"Index"},{"location":"algorithms/greedy_method/#greedy-method","text":"A common strategy used to solve problems. Useful in solving optimization problems, the problems which require minimum or maximum result. Optimizations problems can be solved using the below approaches: * Greedy Method * Dynamic Programming * Branch and Bound","title":"Greedy Method"},{"location":"algorithms/greedy_method/#greedy-method_1","text":"While looping over stuff, check if it is feasible solution to the problem. n = 5 a = [a1, a2, a3, a4, a5] algo greedy(a, n) { for i = 1 to n do { x = select(a); if is_feasible(x) then { solution = solution + x; } } } n = 5 a = [ a1 , a2 , a3 , a4 , a5 ] def greedy ( a , n ): for i in range ( 1 , n + 1 ): x = select ( a ) if is_feasible ( x ): solution = solution + x ;","title":"Greedy Method"},{"location":"algorithms/greedy_method/dijkstra_algorithm/","text":"Dijkstra Algorithm","title":"Dijkstra Algorithm"},{"location":"algorithms/greedy_method/dijkstra_algorithm/#dijkstra-algorithm","text":"","title":"Dijkstra Algorithm"},{"location":"algorithms/greedy_method/huffman_coding/","text":"Huffman Coding A compression algorithm that uses the concepts from Optimal Merge Pattern. Huffman coding is a variable size encoding. Usually each alphabet in ASCII takes 8-bit. Message to transmit: ACCBDAECCDAE Alphabets ASCII A 65 B 66 Alphabets Count Frequency Code A 3 3/12 B 1 1/12 C 4 4/12 D 2 2/12 E 2 2/12","title":"Huffman Coding"},{"location":"algorithms/greedy_method/huffman_coding/#huffman-coding","text":"A compression algorithm that uses the concepts from Optimal Merge Pattern. Huffman coding is a variable size encoding. Usually each alphabet in ASCII takes 8-bit. Message to transmit: ACCBDAECCDAE Alphabets ASCII A 65 B 66 Alphabets Count Frequency Code A 3 3/12 B 1 1/12 C 4 4/12 D 2 2/12 E 2 2/12","title":"Huffman Coding"},{"location":"algorithms/greedy_method/job_sequencing_with_deadlines/","text":"Job Sequencing with Deadlines Greedy method can be used to determine the order or priority of execution of jobs, where each job has an associated deadline and an associated profit, to maximise the total profit. There also might be more jobs than are slots available for their execution, so only a particular combination of jobs which maximise profits must be run. For the purposes of this problem, it is assumed each job takes 1 unit of time. from dataclasses import dataclass @dataclass class Job : job_id : int profit : int deadline : int Example 1 Jobs \\(J_1\\) \\(J_2\\) \\(J_3\\) \\(J_4\\) \\(J_5\\) Profits 20 15 10 5 1 Deadlines 2 2 1 3 3 If the number of slots are 3, only 3 of the above jobs can be scheduled for execution. \\(0 -J_2-> 1 -J_1-> 2 -J_4-> 3\\) First select the jobs with the highest profits, and schedule as late their deadlines allow us. So the sequence of jobs is \\({J_2, J_1, J_4}\\) , and total profit is","title":"Job Sequencing with Deadline"},{"location":"algorithms/greedy_method/job_sequencing_with_deadlines/#job-sequencing-with-deadlines","text":"Greedy method can be used to determine the order or priority of execution of jobs, where each job has an associated deadline and an associated profit, to maximise the total profit. There also might be more jobs than are slots available for their execution, so only a particular combination of jobs which maximise profits must be run. For the purposes of this problem, it is assumed each job takes 1 unit of time. from dataclasses import dataclass @dataclass class Job : job_id : int profit : int deadline : int Example 1 Jobs \\(J_1\\) \\(J_2\\) \\(J_3\\) \\(J_4\\) \\(J_5\\) Profits 20 15 10 5 1 Deadlines 2 2 1 3 3 If the number of slots are 3, only 3 of the above jobs can be scheduled for execution. \\(0 -J_2-> 1 -J_1-> 2 -J_4-> 3\\) First select the jobs with the highest profits, and schedule as late their deadlines allow us. So the sequence of jobs is \\({J_2, J_1, J_4}\\) , and total profit is","title":"Job Sequencing with Deadlines"},{"location":"algorithms/greedy_method/knapsack_problem/","text":"Knapsack Problem Maximizing the profit, by placing various objects with different associated profits and weights inside a knapsack of limited capacity. We must judge based the objects on profit/weight, that is profit per KG of weight.","title":"Knapsack Problem"},{"location":"algorithms/greedy_method/knapsack_problem/#knapsack-problem","text":"Maximizing the profit, by placing various objects with different associated profits and weights inside a knapsack of limited capacity. We must judge based the objects on profit/weight, that is profit per KG of weight.","title":"Knapsack Problem"},{"location":"algorithms/greedy_method/optimal_merge_pattern/","text":"Optimal Merge Pattern Merging is the process of combing two sorted array to form a single large array, this is more precisely called Two-way merge. Merge has a time complexity of \\(\\theta(n + m)\\) . The discussion of optimal merge pattern comes up with, more than two array have to merged pairwise using only Two-way merge. The Greedy Method that should be followed here is that the smaller list must always be merged first, then only then move onto merging larger lists. Merge List A B C D Sizes 6 5 3 2 The best way to merge this would be to start with mergin the smaller lists first and then going ontowards the large one. \\(\\sum_1^n (d_{i} \\times x_{i})\\) , where \\(d_{i}\\) is the distance of each array and \\(x_{i}\\) is the length of the \\(i^{th}\\) array.","title":"Optimal Merge Pattern"},{"location":"algorithms/greedy_method/optimal_merge_pattern/#optimal-merge-pattern","text":"Merging is the process of combing two sorted array to form a single large array, this is more precisely called Two-way merge. Merge has a time complexity of \\(\\theta(n + m)\\) . The discussion of optimal merge pattern comes up with, more than two array have to merged pairwise using only Two-way merge. The Greedy Method that should be followed here is that the smaller list must always be merged first, then only then move onto merging larger lists. Merge List A B C D Sizes 6 5 3 2 The best way to merge this would be to start with mergin the smaller lists first and then going ontowards the large one. \\(\\sum_1^n (d_{i} \\times x_{i})\\) , where \\(d_{i}\\) is the distance of each array and \\(x_{i}\\) is the length of the \\(i^{th}\\) array.","title":"Optimal Merge Pattern"},{"location":"algorithms/greedy_method/prims_and_kruskals/","text":"Prim's and Krushal's Minimum Cost Spanning Tree Graphs are a combinations of vertices and edges. A spanning tree is a subgraph of a graph, which all the vertices but has \\(n - 1\\) edges.","title":"Prim's and Kruskal's"},{"location":"algorithms/greedy_method/prims_and_kruskals/#prims-and-krushals","text":"","title":"Prim's and Krushal's"},{"location":"algorithms/greedy_method/prims_and_kruskals/#minimum-cost-spanning-tree","text":"Graphs are a combinations of vertices and edges. A spanning tree is a subgraph of a graph, which all the vertices but has \\(n - 1\\) edges.","title":"Minimum Cost Spanning Tree"}]}